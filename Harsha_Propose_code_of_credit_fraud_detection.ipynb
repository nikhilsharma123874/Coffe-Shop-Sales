{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilsharma123874/Coffe-Shop-Sales/blob/main/Harsha_Propose_code_of_credit_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei8k2lweLdXq"
      },
      "source": [
        "# Proposed code of Credit Card Fraud Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "btOOBW3X97WV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS-JWnsKQgUA"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZHbTE89BPS9",
        "outputId": "1cb290df-62d9-4696-d959-648f052b7f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Using cached pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyswarms) (1.16.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pyswarms) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from pyswarms) (25.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pyswarms) (6.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Using cached pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "Installing collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=9f4d4a887b68c3755e377cc8f5f67de4981813bc24372eb602c822eb4e6db90d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Retrieves and adds a machine learning toolkit and optimization library for particle-based swarm approaches.\n",
        "!pip install pyswarms scikit-learn\n",
        "# Obtains and incorporates a well-known framework for building and honing deep neural networks.\n",
        "!pip install tensorflow\n",
        "# Obtains and incorporates a high-level interface for neural network model construction.\n",
        "!pip install keras\n",
        "# Gets a gradient-boosting system that is specific to categorical data and adds it.\n",
        "!pip install catboost\n",
        "# Obtains and adds two libraries for explainability and model interpretation.\n",
        "!pip install shap lime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7CHcaruQkxz"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7sD3_wbi1V5"
      },
      "outputs": [],
      "source": [
        "# Loads a popular data analysis module for working with structured datasets in the form of rows and columns.\n",
        "import pandas as pnds\n",
        "# Loads a core library for numerical computing, allowing for sophisticated mathematical functions and quick array operations.\n",
        "import numpy as npy\n",
        "# Opens a visualization package that lets you create customizable static charts, graphs, and plots.\n",
        "import matplotlib.pyplot as mtplt\n",
        "# Adds eye-catching styling and statistical visuals to a data visualization toolkit that is loaded on top of another plotting library.\n",
        "import seaborn as sbrn\n",
        "# Opens a library to generate interactive visualizations for presenting and exploring data in the browser itself.\n",
        "import plotly.express as plty\n",
        "# Provides a tool for normalizing numerical data values to a predetermined range so that the model performs consistently.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Introduces a method that builds and evaluates a predictive model repeatedly to identify the variables that score highest.\n",
        "from sklearn.feature_selection import RFE\n",
        "# Introduces a statistical model that uses a linear connection between inputs and outputs to predict a binary outcome.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# In order to provide random values or sequences for testing or sampling, a module is loaded.\n",
        "import random\n",
        "# Introduces an ensemble-based predictive model that builds several possible courses of action and combines the outcomes.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# In order to construct a model, it brings in a function that divides a dataset into training and evaluation parts.\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Involves a function to determine the percentage of accurate forecasts among all predictions.\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Involves a helper to organize several interactive images into a single figure arrangement.\n",
        "from plotly.subplots import make_subplots\n",
        "# Loads an object that facilitates the creation of personalized visual figures with a variety of chart formats.\n",
        "import plotly.graph_objects as go\n",
        "# Introduces a scoring method that quantifies the degree of interdependence between factors and the desired result.\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "# Introduces tools to compute dependency scores, choose variables based on models, and eliminate features with low variance.\n",
        "from sklearn.feature_selection import VarianceThreshold, RFE, mutual_info_classif\n",
        "# In order to equalize the distribution of the dataset, a method is loaded to create additional samples of underrepresented classes intentionally.\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# Introduces a potent model that ranks the significance of features using several random decision trees.\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# Incorporates functions for computing error matrices and summarizing model results with comprehensive metrics.\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Uses area under the curve metrics to assess performance and compute misclassification matrices.\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
        "# Provides reporting facilities and a number of scoring functions, such as F1, recall, accuracy, and precision.\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "# Opens a deep learning framework to create, train, and assess sophisticated neural network models.\n",
        "import tensorflow as tfl\n",
        "# Introduces a sequential model structure for the orderly stacking of several processing layers.\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Loads a gradient-boosting system that can handle various kinds of data and offers excellent performance with little adjustment.\n",
        "from catboost import CatBoostClassifier\n",
        "# Uses a library to illustrate model predictions by highlighting the attributes that were most important in each choice.\n",
        "import shap\n",
        "# Provides a package to assist make forecasts comprehensible by simplifying complex models.\n",
        "import lime\n",
        "# Introduces a particular section of the interpretability package intended for tabular datasets.\n",
        "import lime.lime_tabular\n",
        "# Opens interactive outputs or web pages in the default web browser by loading a utility.\n",
        "import webbrowser\n",
        "# During execution, loads a module to control program alerts and turn off non-essential messages.\n",
        "import warnings\n",
        "# To keep output clear and concentrated, a filter is set to conceal unnecessary notifications.\n",
        "warnings.filterwarnings('ignore')\n",
        "# Introduces various processing layer types, such as regularization, normalization, and fully connected stages.\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "# Incorporates a monitoring system that stops training when performance deteriorates past a predetermined threshold of tolerance.\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# In order to manage complex neural network calculations and optimizations, a deep learning engine is loaded.\n",
        "import tensorflow as tfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zd6EsLRkmhM",
        "outputId": "c95dde2b-1bc9-40e4-a582-202f3c6a39e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Brings in a tool that allows accessing an online storage service straight from the notebook environment.\n",
        "from google.colab import drive\n",
        "# Linking the notebook to the cloud storage account allows its files to be accessed at the designated folder path.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WArmTeWGQqbH"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5juBxYUk1OL"
      },
      "outputs": [],
      "source": [
        "# Linking the notebook to the cloud storage account allows its files to be accessed at the designated folder path.\n",
        "cdl = pnds.read_csv('/creditcard[1].csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6XjNOsDsyCh"
      },
      "source": [
        "head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "5jcT5Y_KlPSF",
        "outputId": "f3f1e380-df88-4b10-a23a-c8942381a45b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
              "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
              "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
              "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf21788a-c755-4f95-a0a2-1f7b1c0d3815\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf21788a-c755-4f95-a0a2-1f7b1c0d3815')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf21788a-c755-4f95-a0a2-1f7b1c0d3815 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf21788a-c755-4f95-a0a2-1f7b1c0d3815');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4e395352-984a-40f1-ba6b-a716f4566708\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e395352-984a-40f1-ba6b-a716f4566708')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4e395352-984a-40f1-ba6b-a716f4566708 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cdl"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Provides a brief overview of the dataset's contents by displaying the first few entries.\n",
        "cdl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB6DHYSQs0sv"
      },
      "source": [
        "Tail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "collapsed": true,
        "id": "AZz8kOSGldRO",
        "outputId": "5abf508d-a974-4b91-dc8f-cc9a0df6c2fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Time        V1        V2        V3        V4        V5        V6  \\\n",
              "7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n",
              "7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n",
              "7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n",
              "7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n",
              "7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n",
              "\n",
              "            V7        V8        V9  ...       V21       V22       V23  \\\n",
              "7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n",
              "7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n",
              "7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n",
              "7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n",
              "7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n",
              "\n",
              "           V24       V25       V26       V27       V28  Amount  Class  \n",
              "7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n",
              "7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n",
              "7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n",
              "7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n",
              "7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cc4a9bc-39dd-4fb0-9d42-79e9b90995e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7968</th>\n",
              "      <td>10980</td>\n",
              "      <td>1.284388</td>\n",
              "      <td>-0.013181</td>\n",
              "      <td>0.646174</td>\n",
              "      <td>0.198985</td>\n",
              "      <td>-0.568675</td>\n",
              "      <td>-0.526121</td>\n",
              "      <td>-0.448235</td>\n",
              "      <td>-0.167709</td>\n",
              "      <td>1.773223</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.101868</td>\n",
              "      <td>-0.030298</td>\n",
              "      <td>-0.081412</td>\n",
              "      <td>-0.123281</td>\n",
              "      <td>0.278808</td>\n",
              "      <td>1.064001</td>\n",
              "      <td>-0.090181</td>\n",
              "      <td>0.000481</td>\n",
              "      <td>15.95</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7969</th>\n",
              "      <td>10981</td>\n",
              "      <td>1.190428</td>\n",
              "      <td>-0.122329</td>\n",
              "      <td>0.954945</td>\n",
              "      <td>0.267101</td>\n",
              "      <td>-0.971026</td>\n",
              "      <td>-0.652279</td>\n",
              "      <td>-0.612992</td>\n",
              "      <td>-0.003909</td>\n",
              "      <td>1.633117</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015001</td>\n",
              "      <td>0.127027</td>\n",
              "      <td>0.012079</td>\n",
              "      <td>0.534409</td>\n",
              "      <td>0.112179</td>\n",
              "      <td>1.004483</td>\n",
              "      <td>-0.100188</td>\n",
              "      <td>-0.004774</td>\n",
              "      <td>14.95</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7970</th>\n",
              "      <td>10981</td>\n",
              "      <td>-0.725175</td>\n",
              "      <td>0.298202</td>\n",
              "      <td>1.824761</td>\n",
              "      <td>-2.587170</td>\n",
              "      <td>0.283605</td>\n",
              "      <td>-0.016617</td>\n",
              "      <td>0.153659</td>\n",
              "      <td>0.045084</td>\n",
              "      <td>-0.197611</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017097</td>\n",
              "      <td>-0.070535</td>\n",
              "      <td>-0.442861</td>\n",
              "      <td>-0.895837</td>\n",
              "      <td>0.624743</td>\n",
              "      <td>-0.510601</td>\n",
              "      <td>-0.031142</td>\n",
              "      <td>0.025564</td>\n",
              "      <td>12.95</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7971</th>\n",
              "      <td>10981</td>\n",
              "      <td>1.226153</td>\n",
              "      <td>-0.129645</td>\n",
              "      <td>0.735197</td>\n",
              "      <td>0.142752</td>\n",
              "      <td>-0.703245</td>\n",
              "      <td>-0.349641</td>\n",
              "      <td>-0.612641</td>\n",
              "      <td>0.020507</td>\n",
              "      <td>1.648986</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.047936</td>\n",
              "      <td>0.040196</td>\n",
              "      <td>-0.057391</td>\n",
              "      <td>-0.012386</td>\n",
              "      <td>0.187685</td>\n",
              "      <td>1.037786</td>\n",
              "      <td>-0.100081</td>\n",
              "      <td>-0.009869</td>\n",
              "      <td>15.95</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7972</th>\n",
              "      <td>10981</td>\n",
              "      <td>1.145381</td>\n",
              "      <td>-0.059349</td>\n",
              "      <td>0.968088</td>\n",
              "      <td>0.267891</td>\n",
              "      <td>-0.822582</td>\n",
              "      <td>-0.597727</td>\n",
              "      <td>-0.450197</td>\n",
              "      <td>-0.119747</td>\n",
              "      <td>1.338188</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc4a9bc-39dd-4fb0-9d42-79e9b90995e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cc4a9bc-39dd-4fb0-9d42-79e9b90995e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cc4a9bc-39dd-4fb0-9d42-79e9b90995e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-00e7048a-0043-4e25-a019-def027db65d2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00e7048a-0043-4e25-a019-def027db65d2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-00e7048a-0043-4e25-a019-def027db65d2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Shows the dataset's final few entries to see the concluding section.\n",
        "cdl.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMLBTtKs9kI"
      },
      "source": [
        "Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-JG3B5Mlh9K",
        "outputId": "6c48ab78-6fc8-49e9-a928-7616e42aec6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7973, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Displays how many fields and entries there are in the dataset overall.\n",
        "cdl.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tbvg_9Ss_W9"
      },
      "source": [
        "Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nezVp1lBltwO"
      },
      "outputs": [],
      "source": [
        "# Gives an overview of memory information, non-empty counts, and field kinds.\n",
        "cdl.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-udNisPtBU-"
      },
      "source": [
        "Describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iWaH7Qf2l51Q"
      },
      "outputs": [],
      "source": [
        "# Produces statistical metrics for numerical fields, such as distribution, average, and spread.\n",
        "cdl.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diCml8CMp_fi"
      },
      "outputs": [],
      "source": [
        "# Indicates how many rows, in comparison to others, contain exact repetition.\n",
        "cdl.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd9UHm0btLdi"
      },
      "source": [
        "remove duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yps78NeVqVsW"
      },
      "outputs": [],
      "source": [
        "# Only unique records are retained after removing any rows that are exact repeats.\n",
        "cdl.drop_duplicates(inplace=True)\n",
        "print(\"Shape of the dataframe after removing duplicates:\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD17UMwVtPzX"
      },
      "source": [
        "After Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q2DJUCzFrCSQ"
      },
      "outputs": [],
      "source": [
        "# After eliminating duplicates, it displays the updated total number of fields and entries.\n",
        "cdl.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg0qK7KBtUl0"
      },
      "source": [
        "check null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjyXoxCYrfR4"
      },
      "outputs": [],
      "source": [
        "# Determines how many values are missing from each field.\n",
        "cdl.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmYThkXwthTN"
      },
      "source": [
        "EDA Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7EcSrPSi0w6"
      },
      "outputs": [],
      "source": [
        "# Produces two horizontal and two vertical parts, each with its own header, in a multi-panel figure layout.\n",
        "fig = make_subplots(rows=2, cols=2,\n",
        "\n",
        "                    subplot_titles=('Amount Distribution by Class',\n",
        "\n",
        "                                    'Amount Box Plot by Class',\n",
        "\n",
        "                                    'Amount Distribution (Log Scale)',\n",
        "\n",
        "                                    'Amount Statistics by Class'))\n",
        "# Processes values independently for each category by iterating over two category labels.\n",
        "for class_val in [0, 1]:\n",
        "# Extracts a specific number column and filters the data to include only items that fall into the current category.\n",
        "    class_data = cdl[cdl['Class'] == class_val]['Amount']\n",
        "# For the current category, a bar-style frequency diagram with semi-transparency, a fixed bin count, and legend visibility exclusively for the first category is added.\n",
        "    fig.add_trace(go.Histogram(x=class_data, name=f'Class {class_val}',\n",
        "\n",
        "                               opacity=0.7, nbinsx=50, showlegend=(class_val == 0)),\n",
        "                  row=1, col=1)\n",
        "\n",
        "# Incorporates a rectangular statistical plot for the first category's numerical values.\n",
        "fig.add_trace(go.Box(x=cdl[cdl['Class'] == 0]['Amount'], name='Non-Fraud'), row=1, col=2)\n",
        "# Incorporates a rectangle statistical plot for the second category's numerical values.\n",
        "fig.add_trace(go.Box(x=cdl[cdl['Class'] == 1]['Amount'], name='Fraud'), row=1, col=2)\n",
        "# Repeats over two category names to process their numeric values after they have been translated.\n",
        "for class_val in [0, 1]:\n",
        "# Applying a logarithmic adjustment to the chosen numerical values, the data is filtered for the current category.\n",
        "    class_data = cdl[cdl['Class'] == class_val]['Amount']\n",
        "# Includes a semi-transparent frequency graphic of the converted data without legends.\n",
        "    fig.add_trace(go.Histogram(x=npy.log1p(class_data), name=f'Class {class_val} (Log)',\n",
        "                               opacity=0.7, nbinsx=50, showlegend=False),\n",
        "                  row=2, col=1)\n",
        "\n",
        "# Resets the index after classifying the data and determining the average, middle value, and variability for the numerical column.\n",
        "stats = cdl.groupby('Class')['Amount'].agg(['mean', 'median', 'std']).reset_index()\n",
        "# Incorporates a bar diagram that displays the first category's average, middle value, and variability.\n",
        "fig.add_trace(go.Bar(x=['Mean', 'Median', 'Std Dev'],\n",
        "                     y=stats.loc[0, ['mean', 'median', 'std']],\n",
        "                     name='Non-Fraud'), row=2, col=2)\n",
        "# Incorporates a bar diagram that displays the second category's average, middle value, and variability.\n",
        "fig.add_trace(go.Bar(x=['Mean', 'Median', 'Std Dev'],\n",
        "                     y=stats.loc[1, ['mean', 'median', 'std']],\n",
        "                     name='Fraud'), row=2, col=2)\n",
        "# Sets the primary heading, modifies the overall figure dimensions, and places the bars next to each other for comparison.\n",
        "fig.update_layout(height=800,\n",
        "                  width=1200,\n",
        "                  title_text=\"Amount Analysis by Class\",\n",
        "                  barmode='group')\n",
        "# Opens an interactive window with the finished visualization.\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DRk8pL-jNqn"
      },
      "outputs": [],
      "source": [
        "# Makes a new plotting canvas with height and width adjustments to accommodate intricate images.\n",
        "mtplt.figure(figsize=(20, 16))\n",
        "# Produces a table that displays all of the dataset's numerical variables' pairwise statistical correlations.\n",
        "corr_matrix = cdl.corr()\n",
        "# Generates an upper-triangle boolean filter to conceal duplicate values from the relationship table's visual appearance.\n",
        "mask = npy.triu(npy.ones_like(corr_matrix))\n",
        "# Produces a colorful grid with a masked upper triangle, style settings, and feature relationships with values.\n",
        "sbrn.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', center=0,\n",
        "\n",
        "            square=True, mask=mask, cbar_kws={\"shrink\": .8})\n",
        "# Provides context by adding a descriptive header to the top of the image.\n",
        "mtplt.title('Feature Correlation Matrix with Values')\n",
        "# Makes the image visible in the output by rendering it.\n",
        "mtplt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcSidXhunTzz"
      },
      "outputs": [],
      "source": [
        "# Creates a new drawing area with specified height and width to hold the next image.\n",
        "mtplt.figure(figsize=(6, 5))\n",
        "# Produces a bar-style display of the number of entries in a given field for each category.\n",
        "ax = sbrn.countplot(x='Class', data=cdl)\n",
        "# Adds a heading that explains what the chart depicts above the image.\n",
        "mtplt.title('Distribution of Class')\n",
        "# Adds numerical labels to the top of each rectangle bar in the image by looping through them.\n",
        "for p in ax.patches:\n",
        "# Returns the current bar's height as a whole number.\n",
        "    height = int(p.get_height())\n",
        "# Adjusts the font and alignment to position the height value above the bar's center.\n",
        "    ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                               ha='center', va='bottom', fontsize=11)\n",
        "# Shows the finished image in the output field.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rRax9BQNmMI_"
      },
      "outputs": [],
      "source": [
        "# Produces an interactive frequency chart with a specified number of bins for grouping data, a custom header, and axis labels that illustrate how a numerical column is distributed across various categories.\n",
        "fig = plty.histogram(cdl, x=\"Amount\", color=\"Class\",\n",
        "\n",
        "                   title=\"Distribution of Amount by Class\",\n",
        "\n",
        "                   labels={\"Amount\": \"Amount\", \"Class\": \"Class\"},\n",
        "\n",
        "                   nbins=50)\n",
        "\n",
        "# Modifies the heading that appears above the category legend.\n",
        "fig.update_layout(legend_title_text='Class')\n",
        "# Modifies the chart legend's category names to substitute descriptive language for numeric labels.\n",
        "fig.for_each_trace(lambda t: t.update(name='Fraud' if t.name == '1' else 'Non-Fraud'))\n",
        "# To improve the presentation of significant value discrepancies, the vertical axis is changed to a logarithmic scale.\n",
        "fig.update_yaxes(type=\"log\")\n",
        "# In the output area, the interactive chart is displayed.\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s-t7kY7UvaOF"
      },
      "outputs": [],
      "source": [
        "# Creates an interactive bar-style frequency plot with a custom heading, custom axis text, normalized height values, and a predetermined number of group intervals to compare the distribution of a particular variable across categories.\n",
        "fig = plty.histogram(cdl, x=\"Time\", color=\"Class\",\n",
        "\n",
        "                   title=\"Time of Transaction vs Class\",\n",
        "\n",
        "                   labels={\"Time\": \"Time of Transaction\", \"Class\": \"Class\"},\n",
        "\n",
        "                   histnorm='density',\n",
        "\n",
        "                   nbins=100)\n",
        "\n",
        "# Modifies the category name label that appears above the legend.\n",
        "fig.update_layout(legend_title_text='Class')\n",
        "# Adds labels with descriptive text in place of the legend's numerical category identifiers.\n",
        "fig.for_each_trace(lambda t: t.update(name='Fraud' if t.name == '1' else 'Non-Fraud'))\n",
        "# The interactive chart is rendered in the output area.\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bwsiTkmDVq5"
      },
      "source": [
        "Seperate features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7DifEsf68sS"
      },
      "outputs": [],
      "source": [
        "# Remove rows with missing values in the 'Class' column\n",
        "cdl.dropna(subset=['Class'], inplace=True)\n",
        "\n",
        "# Produces a dataset with every feature—aside from the target variable.\n",
        "X = cdl.drop('Class', axis=1)\n",
        "# Keeps the target variable apart for training and testing the model.\n",
        "y = cdl['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXufIgLRITfu"
      },
      "source": [
        "Feature selection techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG9xYuzCOBKK"
      },
      "outputs": [],
      "source": [
        "# Sets up a feature filter that eliminates variables with extremely low sample variability.\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "# Uses the filter to ensure that only variables that satisfy the variability criterion are retained.\n",
        "# Apply VarianceThreshold on X after dropping NaNs based on the 'Class' column\n",
        "X_var = selector.fit_transform(X)\n",
        "# Gets the variables that passed the variability check and their names.\n",
        "selected_cols_var = X.columns[selector.get_support()]\n",
        "# Makes a new table with just the variables that were kept and their original names.\n",
        "# Ensure index alignment with y after dropping NaNs\n",
        "X_var_cdl = pnds.DataFrame(X_var, columns=selected_cols_var, index=X.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojJugz0qIjuV"
      },
      "outputs": [],
      "source": [
        "# Ensure X_var_cdl and y have the same index before fitting RFE\n",
        "common_indices = X_var_cdl.index.intersection(y.index)\n",
        "X_var_cdl_filtered = X_var_cdl.loc[common_indices]\n",
        "y_filtered = y.loc[common_indices]\n",
        "\n",
        "# Using a linear classification technique, it repeatedly builds a model, establishing a feature selection process that retains the top variables.\n",
        "rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=18)\n",
        "# Fits the target values and the filtered dataset to the selection procedure.\n",
        "rfe.fit(X_var_cdl_filtered, y_filtered)\n",
        "# Returns the variables' names that were deemed most crucial.\n",
        "selected_features_rfe = X_var_cdl_filtered.columns[rfe.support_]\n",
        "# Before showing the selected variable names, a header is printed.\n",
        "print(\"\\nSelected Features by RFE:\")\n",
        "# Outputs the readable list of selected variable names.\n",
        "print(selected_features_rfe.tolist())\n",
        "# Produces a fresh dataset with just the selected variables for additional processing.\n",
        "X_selected = X_var_cdl_filtered[selected_features_rfe]\n",
        "\n",
        "\n",
        "# Returns the ranking values that the feature selection procedure assigned to each variable.\n",
        "ranking = rfe.ranking_\n",
        "# Constructs a horizontal bar chart with custom axis labels, a heading, color mapping, and figure size modifications that shows each variable and its importance ranking.\n",
        "fig = plty.bar(\n",
        "    x=ranking,\n",
        "    y=X_var_cdl_filtered.columns,  # Show all features ranked by RFE\n",
        "    orientation='h',\n",
        "    labels={'x': 'RFE Ranking (1 = Selected Feature)', 'y': 'Features'},\n",
        "    title='RFE Feature Ranking',\n",
        "    color=ranking,\n",
        "    color_continuous_scale='Blues',\n",
        "    height=600,\n",
        "    width=800,\n",
        ")\n",
        "# Flips the vertical axis so that the variables with the highest rankings are at the top.\n",
        "fig.update_yaxes(autorange='reversed')\n",
        "# Shows the finished interactive bar graph.\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7TRbEYGH5pY"
      },
      "outputs": [],
      "source": [
        "# Prepares the selected set of variables for processing by converting them from a tabular structure into an array format.\n",
        "X_selected_npy = X_selected.to_numpy()\n",
        "# Prepares the target variable for processing by converting it into an array format.\n",
        "y_npy = y.to_numpy()\n",
        "# Uses an information theory approach to determine dependency scores between each selected variable and the desired result.\n",
        "mutual_info = mutual_info_classif(X_selected_npy, y_npy, random_state=42)\n",
        "# Uses the names of the selected variables to store the determined dependence scores in a labeled one-dimensional structure.\n",
        "mutual_info_series = pnds.Series(mutual_info, index=selected_features_rfe)\n",
        "# To facilitate comparison, the dependency scores are arranged from highest to lowest.\n",
        "mutual_info_series.sort_values(ascending=False, inplace=True)\n",
        "# Before displaying the sorted dependency scores, a heading is printed.\n",
        "print(\"\\nMutual Information Scores (sorted):\")\n",
        "# Outputs all selected variables' ordered dependency scores.\n",
        "print(mutual_info_series)\n",
        "# Creates a new drawing area for the next visual with the desired width and height.\n",
        "mtplt.figure(figsize=(10, 5))\n",
        "# Creates a vertical bar chart that displays each selected variable's dependence scores.\n",
        "mutual_info_series.plot(kind='bar')\n",
        "# Indicates what the values mean by adding a label to the vertical axis.\n",
        "mtplt.ylabel(\"Mutual Information Score\")\n",
        "# In order to clarify what is displayed, a descriptive heading is added above the chart.\n",
        "mtplt.title(\"Mutual Information of Selected Features\")\n",
        "# Generates the finished chart for output viewing.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52OQFqtyIOpX"
      },
      "source": [
        "Minimax scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sad-AeTx8kt2"
      },
      "outputs": [],
      "source": [
        "# Generates a value normalization object that ensures all features fall inside a predetermined range.\n",
        "scaler = MinMaxScaler()\n",
        "# Converts the selected variables into the new range by fitting the normalizer to them.\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "# Uses the original feature names to transform the normalized array back into a labeled table.\n",
        "X_scaled_cdl = pnds.DataFrame(X_scaled, columns=selected_features_rfe)\n",
        "# Before displaying a glimpse of the normalized dataset, a heading is printed.\n",
        "print(\"\\nScaled Data (first 5 rows):\")\n",
        "# Shows the normalized dataset's initial few records.\n",
        "display(X_scaled_cdl.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyA1P3f-TfJF"
      },
      "source": [
        "Balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-ut_i7gQMUi"
      },
      "outputs": [],
      "source": [
        "# To get ready for class balancing operations, a duplicate of the normalized dataset is created.\n",
        "cdl_balancing = X_scaled_cdl.copy()\n",
        "# In the duplicate dataset, the outcome variable is added as a new column.\n",
        "cdl_balancing['target'] = y.values\n",
        "# All rows that fall into the first outcome category are filtered and stored.\n",
        "class_0 = cdl_balancing[cdl_balancing['target'] == 0]\n",
        "# All rows that fall within the second outcome category are filtered and stored.\n",
        "class_1 = cdl_balancing[cdl_balancing['target'] == 1]\n",
        "# Takes half of the initial count to determine how many records should be kept for the first category.\n",
        "undersample_size = int(len(class_0) * 0.5)\n",
        "# Based on the determined size, a subset of the data from the first category is chosen at random.\n",
        "class_0_under = class_0.sample(undersample_size, random_state=42)\n",
        "# Determines how many records should be made for the second category by dividing the size of the first category.\n",
        "oversample_size = int(len(class_0_under))\n",
        "# Chooses records at random from the second category and replaces them to reach the required number.\n",
        "class_1_over = class_1.sample(oversample_size, replace=True, random_state=42)\n",
        "# Combines the first category's reduction and the second category's expansion, then randomly shuffles the rows.\n",
        "cdl_balanced = pnds.concat([class_0_under, class_1_over], axis=0).sample(frac=1, random_state=42)\n",
        "# Removes the outcome column to divide the balanced dataset into input variables.\n",
        "X_balanced = cdl_balanced.drop('target', axis=1)\n",
        "# Only the balanced dataset's outcome column is saved for further use.\n",
        "y_balanced = cdl_balanced['target']\n",
        "# After balancing, a header is printed before the counts of each category are displayed.\n",
        "print(\"\\nClass distribution after balancing:\")\n",
        "# After the balancing process, the number of records in each category is shown.\n",
        "print(y_balanced.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxnXYqBwTL_h"
      },
      "source": [
        "Split Train Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnyxMQsWTKEm"
      },
      "outputs": [],
      "source": [
        "# Divide the prepared dataset into training and testing parts, keeping 26% aside for testing and ensuring repeatable results with a fixed seed.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "\n",
        "    X_balanced, y_balanced, test_size=0.26, random_state=42\n",
        ")\n",
        "# Show the training portion's goal size as well as the quantity of samples and features.\n",
        "print(\"\\nTraining set size:\", X_train.shape, y_train.shape)\n",
        "# Show the goal size as well as the quantity of features and samples for the testing section.\n",
        "print(\"Testing set size:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phxPM3Ck3mQD"
      },
      "source": [
        "# Apply model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjYFp4Z33rWS"
      },
      "source": [
        "# Extra trees classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmBeZ3yWzbwc"
      },
      "outputs": [],
      "source": [
        "# To increase accuracy and decrease variation, start a prediction model that combines several randomized decision trees.\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et_model_final = ExtraTreesClassifier(\n",
        "# Indicate how many students will be in the group overall.\n",
        "     n_estimators=200,\n",
        "# Limit how many levels of decision-making each learner can use to manage complexity.\n",
        "    max_depth=20,\n",
        "# To separate a node in the structure, at least this many records are needed.\n",
        "    min_samples_split=8,\n",
        "# Define the bare minimum of records required in a terminal branch.\n",
        "    min_samples_leaf=5,\n",
        "# When building divisions in the structure, restrict the number of input characteristics that are verified.\n",
        "    max_features=12,\n",
        "# Choose whether to use the entire dataset or just a few chosen samples for creating learners.\n",
        "    bootstrap=False,\n",
        "# To handle unequal class presence, automatically modify the priority values for each category.\n",
        "    class_weight='balanced',\n",
        "# Adjust the seed value to enable consistent replication of the results.\n",
        "    random_state=42,\n",
        "# To speed up computation, enable the use of all available processing cores.\n",
        "    n_jobs=-1)\n",
        "# To enable the model to identify patterns and correlations, fit it to the learning dataset that has been provided.\n",
        "et_model_final.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGZY8ADe369U"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWPfh6iywsV6"
      },
      "outputs": [],
      "source": [
        "# Produce outcome predictions for the input records used during learning by applying the trained forest-based ensemble.\n",
        "y_pred_train = et_model_final.predict(X_train)\n",
        "# Show a headline stating that the values below are assessment metrics for the dataset's learning section.\n",
        "print(\"Extra Trees Classifier Results (Training Set):\")\n",
        "# By contrasting the first results with the anticipated ones, display the percentage of accurate identifications.\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "# Display the proportion of accurately identified positive cases to all cases with a positive label.\n",
        "print(\"Precision:\", precision_score(y_train, y_pred_train))\n",
        "# Display the percentage of real positive cases that the system was able to identify.\n",
        "print(\"Recall:\", recall_score(y_train, y_pred_train))\n",
        "# Calculate their harmonic average to demonstrate the overall harmony between completeness and accuracy.\n",
        "print(\"F1 Score:\", f1_score(y_train, y_pred_train))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwCoy4Io1TOY"
      },
      "outputs": [],
      "source": [
        "# Create a table that contrasts the output classifications from the system with the actual category allocations.\n",
        "cm_train = confusion_matrix(y_train, y_pred_train)\n",
        "# To get ready for visual representation, make a blank drawing canvas with the desired width and height.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Create a colorful grid plot with values displayed and color shading applied to display the classification results table.\n",
        "sbrn.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "# Indicate the system's outcome categories by labeling the items on the horizontal axis.\n",
        "            xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
        "# Indicate the ground truth categories by labeling the entries on the vertical axis.\n",
        "            yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
        "# Give the visualization a heading that explains its purpose.\n",
        "mtplt.title('Confusion Matrix (Training Set)')\n",
        "# To make it clear what the horizontal values mean, give the bottom axis a descriptor.\n",
        "mtplt.xlabel('Predicted Label')\n",
        "# To make it clear what the vertical values mean, give the side axis a descriptor.\n",
        "mtplt.ylabel('Actual Label')\n",
        "# Render the finished image so the user can see it.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsSSInBg11dp"
      },
      "outputs": [],
      "source": [
        "# For each case in the training data, determine the probability scores for the positive class.\n",
        "y_prob_train = et_model_final.predict_proba(X_train)[:, 1]\n",
        "# To plot the ROC curve, find the threshold values, true positive rates, and false positive rates.\n",
        "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_prob_train)\n",
        "# To describe the model's performance, calculate the Area Under the ROC Curve (AUC).\n",
        "roc_auc_train = roc_auc_score(y_train, y_prob_train)\n",
        "# To see the ROC curve, make a plotting space of the specified size.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Sketch the line of the ROC curve that illustrates the trade-off between specificity and sensitivity.\n",
        "mtplt.plot(fpr_train, tpr_train, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_train)\n",
        "# For comparison, add a diagonal dashed line that represents random guessing.\n",
        "mtplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "# To meet the needs of the ROC plot, set the horizontal axis boundaries between 0 and 1.\n",
        "mtplt.xlim([0.0, 1.0])\n",
        "# To guarantee complete curve visualization, set the vertical axis limits just a bit above 1.\n",
        "mtplt.ylim([0.0, 1.05])\n",
        "# Indicate the percentage of inaccurate positive predictions by labeling the horizontal axis.\n",
        "mtplt.xlabel('False Positive Rate')\n",
        "# Indicate the percentage of successfully identified positive cases by labeling the vertical axis.\n",
        "mtplt.ylabel('True Positive Rate')\n",
        "# Give the graph a title that clarifies it is a ROC curve for the training set.\n",
        "mtplt.title('Receiver Operating Characteristic (ROC) Curve (Training Set)')\n",
        "# To view the ROC curve and its AUC value, display the legend in the lower right corner.\n",
        "mtplt.legend(loc=\"lower right\")\n",
        "# To enable viewing, render the finished plot.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPi40OKF4EzJ"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShjiKq8_z0X8"
      },
      "outputs": [],
      "source": [
        "# Use the trained Extra Trees model to produce the expected class labels for the evaluation dataset that has not yet been observed.\n",
        "y_pred_et_final = et_model_final.predict(X_test)\n",
        "# To show that the following printed values are the Extra Trees classifier's performance results, display a heading.\n",
        "print(\"Extra Trees Classifier Results:\")\n",
        "# Determine the model's overall accuracy by printing the percentage of all forecasts that were accurate.\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_et_final))\n",
        "# Determine the precision by calculating and printing the ratio of accurately predicted positive cases to all predicted positives.\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_et_final))\n",
        "# Determine and print the recall, or the percentage of real positive cases that were accurately identified.\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_et_final))\n",
        "# To summarize the balance between precision and recall, compute and report the harmonic mean of the two metrics.\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_et_final))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRX0A0VK2WlR"
      },
      "outputs": [],
      "source": [
        "# Make a table that displays the counts of true positives, true negatives, false positives, and false negatives by contrasting the evaluation dataset's actual labels with the labels predicted by the model.\n",
        "cm_test = confusion_matrix(y_test, y_pred_et_final)\n",
        "# To make the plot easier to read, create a new figure window with the appropriate measurements.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Without a color bar, plot the confusion matrix as a color-coded grid with numerical counts in each cell. Then, give the expected and actual categories meaningful labels.\n",
        "sbrn.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "\n",
        "            xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
        "\n",
        "            yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
        "# To show that the confusion matrix is related to the model's performance on the test dataset, add a title.\n",
        "mtplt.title('Confusion Matrix (Test Set)')\n",
        "# Label the horizontal axis with a description of the anticipated classes.\n",
        "mtplt.xlabel('Predicted Label')\n",
        "# Give the vertical axis a label that describes the dataset's real classes.\n",
        "mtplt.ylabel('Actual Label')\n",
        "# Show the plot to see how well the model performs in terms of accurate predictions and classification mistakes.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1CkbHKQ2kzh"
      },
      "outputs": [],
      "source": [
        "# Using the output of the trained algorithm on the unseen dataset, determine the likelihood scores for the positive category.\n",
        "y_prob_test = et_model_final.predict_proba(X_test)[:, 1]\n",
        "# Establish the plotting coordinates for the trade-off between specificity and sensitivity across different thresholds.\n",
        "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_prob_test)\n",
        "# Determine a single-value statistic that sums up the two categories' total separability.\n",
        "roc_auc_test = roc_auc_score(y_test, y_prob_test)\n",
        "# To improve visual clarity, start with a new drawing canvas that has established proportions.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Plot the classifier's quality score and performance line that illustrates how it differentiates across classes.\n",
        "mtplt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_test)\n",
        "# To depict an entirely random decision maker, draw a diagonal reference line.\n",
        "mtplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "# Establish the horizontal measurement axis's lower and upper boundaries.\n",
        "mtplt.xlim([0.0, 1.0])\n",
        "# Define the vertical measurement axis's lower and upper bounds.\n",
        "mtplt.ylim([0.0, 1.05])\n",
        "# Give the horizontal measurement axis a title that explains what it stands for.\n",
        "mtplt.xlabel('False Positive Rate')\n",
        "# Give the vertical measurement axis a title that explains what it stands for.\n",
        "mtplt.ylabel('True Positive Rate')\n",
        "# Indicate in the title how this image pertains to the model's evaluation stage.\n",
        "mtplt.title('Receiver Operating Characteristic (ROC) Curve (Test Set)')\n",
        "# To explain the plotted elements, display a little key in the lower right corner.\n",
        "mtplt.legend(loc=\"lower right\")\n",
        "# Render the entire image so that it can be viewed.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GjF-AolVqWI"
      },
      "source": [
        "# ANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EMN6gbJ07_V6"
      },
      "outputs": [],
      "source": [
        "# Generates a blank deep learning container for sequentially stacking computational layers.\n",
        "ann_model = Sequential()\n",
        "# Defines the dimensionality of incoming samples and uses ReLU activation to insert the first fully connected computing stage with 128 processing units.\n",
        "ann_model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "# Stabilizes and accelerates learning by normalizing activations within each mini-batch.\n",
        "ann_model.add(BatchNormalization())\n",
        "# To avoid overfitting during learning, a portion of the neuron connections are randomly disabled.\n",
        "ann_model.add(Dropout(0.25))\n",
        "# Activates ReLU and adds a second fully connected computing stage with 64 CPUs.\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "# Normalization is applied again to keep feature distributions steady.\n",
        "ann_model.add(BatchNormalization())\n",
        "# To improve generalization, a fraction of neuron outputs is once again randomly removed.\n",
        "ann_model.add(Dropout(0.25))\n",
        "# Uses ReLU activation to add a third fully connected computing stage with 32 processor units.\n",
        "ann_model.add(Dense(32, activation='relu'))\n",
        "# Normalizes the preceding step's outputs.\n",
        "ann_model.add(BatchNormalization())\n",
        "# To manage complexity and prevent data memorization, temporarily reduce 20% of the neuron outputs.\n",
        "ann_model.add(Dropout(0.2))\n",
        "# Incorporates a 16-processor, fully-connected computing stage with ReLU activation.\n",
        "ann_model.add(Dense(16, activation='relu'))\n",
        "# Normalizes once more to keep the training process stable.\n",
        "ann_model.add(BatchNormalization())\n",
        "# Adds a sigmoid activation and a single processing unit to the final output stage to generate probability values ranging from 0 to 1.\n",
        "ann_model.add(Dense(1, activation='sigmoid'))\n",
        "# For weight updates, a well-liked gradient-based optimization technique with a tiny step size is selected.\n",
        "optimizer = tfl.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# Sets up the optimizer, binary classification loss function, and evaluation metrics to monitor in order to get the model ready for training.\n",
        "ann_model.compile(\n",
        "\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tfl.keras.metrics.Precision(), tfl.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Restores the optimal weight state and establishes a rule to end training early if performance on unseen data stops getting better.\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Uses tiny groups of 32 samples, saving 20% for validation, and employs the early stopping condition to train the network with the provided data for a maximum of 20 iterations over the dataset.\n",
        "history_ann = ann_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "# Uses unseen data to test the trained network and records the results in terms of loss, recall, precision, and classification accuracy.\n",
        "loss_ann, accuracy_ann, precision_ann, recall_ann = ann_model.evaluate(X_test, y_test, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQG0UrwvVw0o"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCTHS5vLRsqt"
      },
      "outputs": [],
      "source": [
        "# Uses the trained deep learning model to provide probability outputs for the training input data.\n",
        "y_pred_prob_train_ann = ann_model.predict(X_train)\n",
        "# Using a threshold of 0.5, the projected probabilities are transformed into binary outcomes.\n",
        "y_pred_train_ann = (y_pred_prob_train_ann > 0.5).astype(\"int32\")\n",
        "# Shows a header stating that the metrics listed below are for evaluating the training dataset.\n",
        "print(\"ANN Model Evaluation (Training Set):\")\n",
        "# Displays the percentage of training dataset predictions that were accurate.\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train_ann))\n",
        "# Indicates what percentage of affirmative identifications were truly accurate.\n",
        "print(\"Precision:\", precision_score(y_train, y_pred_train_ann))\n",
        "# Indicates the percentage of real positives that were accurately detected.\n",
        "print(\"Recall:\", recall_score(y_train, y_pred_train_ann))\n",
        "# To balance both measures, it shows the precision and recall harmonic means.\n",
        "print(\"F1 Score:\", f1_score(y_train, y_pred_train_ann))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXtALlWUV25o"
      },
      "outputs": [],
      "source": [
        "# For every class in the training dataset, a table displaying the numbers of accurate and inaccurate predictions is created.\n",
        "cm_train_ann = confusion_matrix(y_train, y_pred_train_ann)\n",
        "# Adjusts the figure's proportions to make the plot readable and large.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Creates a heatmap with numerical annotations for every cell to show the confusion matrix visually.\n",
        "sbrn.heatmap(cm_train_ann, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "# Labels for the expected classes on the horizontal axis.\n",
        "            xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
        "# Labels for the actual classes displayed on the vertical axis.\n",
        "            yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
        "# To specify the kind of matrix and the dataset it refers to, a descriptive title is added.\n",
        "mtplt.title('Confusion Matrix (ANN Model - Training Set)')\n",
        "# Indicates the anticipated category on the horizontal axis.\n",
        "mtplt.xlabel('Predicted Label')\n",
        "# Indicates the actual category on the vertical axis.\n",
        "mtplt.ylabel('Actual Label')\n",
        "# Shows the finished plot.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKpRhLD9WMgs"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of points required to depict the training data's performance trade-off between false alerts and correct positive detection.\n",
        "fpr_train_ann, tpr_train_ann, thresholds_train_ann = roc_curve(y_train, y_pred_prob_train_ann)\n",
        "# Determine the area under the curve, or classification skill, as a numerical value.\n",
        "roc_auc_train_ann = roc_auc_score(y_train, y_pred_prob_train_ann)\n",
        "# Adjust the figure size such that the next visualization is big and simple to understand.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# With the score shown in the legend, create the main line that illustrates the model's link between sensitivity and fall-out.\n",
        "mtplt.plot(fpr_train_ann, tpr_train_ann, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_train_ann)\n",
        "# Sketch a diagonal reference line that depicts the random guessing performance.\n",
        "mtplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "# Assign the horizontal range from the lowest to the highest value that can be found.\n",
        "mtplt.xlim([0.0, 1.0])\n",
        "# To improve spacing, set the vertical range just a bit over the upper limit.\n",
        "mtplt.ylim([0.0, 1.05])\n",
        "# Indicate the percentage of erroneous alarms by labeling the bottom axis.\n",
        "mtplt.xlabel('False Positive Rate')\n",
        "# Indicate the percentage of accurate positive identifications by labeling the left axis.\n",
        "mtplt.ylabel('True Positive Rate')\n",
        "# Include a title outlining the contents of this image and the dataset it pertains to.\n",
        "mtplt.title('Receiver Operating Characteristic (ROC) Curve (ANN Model - Training Set)')\n",
        "# Show the legend in the visual's lower right corner.\n",
        "mtplt.legend(loc=\"lower right\")\n",
        "# Make the image available for viewing.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ0XQlUMVzVy"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlCchIILAFGN"
      },
      "outputs": [],
      "source": [
        "# Use the trained network to produce the expected likelihoods for every record in the unseen dataset.\n",
        "y_pred_prob_ann = ann_model.predict(X_test)\n",
        "# Cast the likelihood values to whole numbers after converting them into discrete categories by determining whether they surpass the predetermined threshold.\n",
        "y_pred_ann = (y_pred_prob_ann > 0.5).astype(\"int32\")\n",
        "# Use the harmonic mean of both measures to assess how well the model's findings balance completeness and accuracy.\n",
        "f1_ann = f1_score(y_test, y_pred_ann)\n",
        "# Write a summary in organized text that includes important quality indicators and comprehensive statistics for every category.\n",
        "classification_rep_ann = classification_report(y_test, y_pred_ann)\n",
        "# To show the outcomes of this specific deep learning method, print a heading.\n",
        "print(\"\\nANN Model Evaluation:\")\n",
        "# Display the calculated error value that shows the difference between the expected results and the model's predictions.\n",
        "print(f\"Loss: {loss_ann}\")\n",
        "# Show the percentage of accurate forecasts in relation to all cases.\n",
        "print(f\"Accuracy: {accuracy_ann}\")\n",
        "# Show the percentage of all positive predictions that were accurately detected.\n",
        "print(f\"Precision: {precision_ann}\")\n",
        "# Display the percentage of successful detections that were real positives.\n",
        "print(f\"Recall: {recall_ann}\")\n",
        "# To gain a better grasp of the model quality, output the harmonic mean metric that was previously calculated.\n",
        "print(f\"F1 Score: {f1_ann}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGAHppoVWwNq"
      },
      "outputs": [],
      "source": [
        "# Create a table that contrasts the actual categories for the unseen dataset with the categories predicted by the model.\n",
        "cm_test_ann = confusion_matrix(y_test, y_pred_ann)\n",
        "# To improve visibility, make a new plotting area with the desired width and height.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Label rows and columns for expected vs. real, and display the comparison table as a colored grid with numbers.\n",
        "sbrn.heatmap(cm_test_ann, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "\n",
        "            xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
        "\n",
        "            yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
        "# Include a heading that clarifies that the plot is a category comparison chart for the outcomes of the neural network on data that hasn't been seen.\n",
        "mtplt.title('Confusion Matrix (ANN Model - Test Set)')\n",
        "# Indicate what the model has guessed by labeling the horizontal axis.\n",
        "mtplt.xlabel('Predicted Label')\n",
        "# Indicate what the real reality was by labeling the vertical axis.\n",
        "mtplt.ylabel('Actual Label')\n",
        "# Present the finished visualization to the user.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW3LOgqLYCPt"
      },
      "outputs": [],
      "source": [
        "# Uses actual and expected probability values to determine the performance curve's horizontal and vertical coordinates as well as decision thresholds.\n",
        "fpr_test_ann, tpr_test_ann, thresholds_test_ann = roc_curve(y_test, y_pred_prob_ann)\n",
        "# Determines the entire region beneath the performance curve for assessment.\n",
        "roc_auc_test_ann = roc_auc_score(y_test, y_pred_prob_ann)\n",
        "# Constructs a new visual area with the desired height and width.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Displays the model's performance curve with a label indicating the calculated score, a specified shade, and a line width.\n",
        "mtplt.plot(fpr_test_ann, tpr_test_ann, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_test_ann)\n",
        "# Adds a diagonal reference line with a different dashed style, width, and shade to indicate random chance.\n",
        "mtplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "# Limits the range of values on the horizontal axis from beginning to ending.\n",
        "mtplt.xlim([0.0, 1.0])\n",
        "# For clarity, make the vertical axis range just over the maximum value.\n",
        "mtplt.ylim([0.0, 1.05])\n",
        "# Gives the horizontal axis a meaningful label.\n",
        "mtplt.xlabel('False Positive Rate')\n",
        "# Gives the vertical axis a meaningful label.\n",
        "mtplt.ylabel('True Positive Rate')\n",
        "# Indicates the model type and dataset chunk by setting the visual's name.\n",
        "mtplt.title('Receiver Operating Characteristic (ROC) Curve (ANN Model - Test Set)')\n",
        "# Puts the label for the curve in the lower right corner.\n",
        "mtplt.legend(loc=\"lower right\")\n",
        "# Shows the last image on the screen.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iPlGqUfcQyH"
      },
      "source": [
        "# CatBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0qU-Z8-D-7uF"
      },
      "outputs": [],
      "source": [
        "# Generates a gradient boosting model instance for numerical and categorical features.\n",
        "catboost_model = CatBoostClassifier(\n",
        "# Defines how many boosting iterations are allowed.\n",
        "    iterations=100,\n",
        "# Establishes the maximum tree depth for every round of boosting.\n",
        "    depth=10,\n",
        "# Prevents overfitting by regulating the regularization strength.\n",
        "    l2_leaf_reg=3,\n",
        "# Indicates the classification's objective function.\n",
        "    loss_function='Logloss',\n",
        "# Selects the assessment metric to monitor throughout training.\n",
        "    eval_metric='Accuracy',\n",
        "# To ensure reproducibility, the randomization seed is fixed.\n",
        "    random_state=42,\n",
        "# During model training, detailed output is made possible.\n",
        "    verbose=1,\n",
        "# If there is no improvement after the specified number of rounds, training is stopped early.\n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "#The model is trained using the training set, validated using the test set, and early halting is used if the validation score does not increase.\n",
        "catboost_model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX-Dn9jccdEa"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZg9WccwauL3"
      },
      "outputs": [],
      "source": [
        "# Use the trained gradient boosting model to create predicted categories for the training data.\n",
        "y_pred_train_catboost = catboost_model.predict(X_train)\n",
        "# Show a heading stating that the training dataset is represented by the following results.\n",
        "print(\"CatBoost Classifier Results (Training Set):\")\n",
        "# Determine and display the percentage of accurate predictions over all samples.\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train_catboost))\n",
        "# Determine and show the proportion of pertinent positive predictions to all of the positive predictions that were made.\n",
        "print(\"Precision:\", precision_score(y_train, y_pred_train_catboost))\n",
        "# Determine the ratio of pertinent positive predictions to all of the positive predictions that were made, then present the results.\n",
        "print(\"Recall:\", recall_score(y_train, y_pred_train_catboost))\n",
        "# Calculate and show the combined metric that strikes a balance between recall and precision.\n",
        "print(\"F1 Score:\", f1_score(y_train, y_pred_train_catboost))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GkzqAftdDrj"
      },
      "outputs": [],
      "source": [
        "# Make a summary table that contrasts the training data's true and anticipated classes.\n",
        "cm_train_catboost = confusion_matrix(y_train, y_pred_train_catboost)\n",
        "# To ensure visual clarity, prepare a plotting area of the designated size.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Display a numerical table with color coding, designating rows and columns for actual and anticipated courses.\n",
        "sbrn.heatmap(cm_train_catboost, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "\n",
        "            xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
        "\n",
        "            yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
        "# To indicate that this is the summary of the training section using the designated model, add a descriptive header.\n",
        "mtplt.title('Confusion Matrix (CatBoost Model - Training Set)')\n",
        "# To display the model's guesses, label the horizontal axis.\n",
        "mtplt.xlabel('Predicted Label')\n",
        "# To display the actual categories, label the vertical axis.\n",
        "mtplt.ylabel('Actual Label')\n",
        "# Show the completed visualization.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV2xgzNQdJ_6"
      },
      "outputs": [],
      "source": [
        "# Get the training dataset's estimated likelihoods for the positive class.\n",
        "y_pred_prob_train_catboost = catboost_model.predict_proba(X_train)[:, 1]\n",
        "# Determine the positions at which the trade-off curve between false alarm rate and sensitivity is plotted using training data.\n",
        "fpr_train_catboost, tpr_train_catboost, thresholds_train_catboost = roc_curve(y_train, y_pred_prob_train_catboost)\n",
        "# Use the area under the curve to calculate the model's overall performance metric.\n",
        "roc_auc_train_catboost = roc_auc_score(y_train, y_pred_prob_train_catboost)\n",
        "# Set up a new plotting window with a predetermined height and width.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Plot the performance curve with a legend displaying the calculated score, along with a specific color and line width.\n",
        "mtplt.plot(fpr_train_catboost, tpr_train_catboost, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_train_catboost)\n",
        "# To illustrate random categorization performance, draw a diagonal reference line.\n",
        "mtplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "# Make sure the horizontal axis spans the entire 0–1 range.\n",
        "mtplt.xlim([0.0, 1.0])\n",
        "# To improve visual spacing, keep the vertical axis little above 1.\n",
        "mtplt.ylim([0.0, 1.05])\n",
        "# Put a label on the horizontal axis that shows the false alarm rate.\n",
        "mtplt.xlabel('False Positive Rate')\n",
        "# Indicate the rate of accurately detected positives by labeling the vertical axis.\n",
        "mtplt.ylabel('True Positive Rate')\n",
        "# Include a title that explains the model context and the content of the chart.\n",
        "mtplt.title('Receiver Operating Characteristic (ROC) Curve (CatBoost Model - Training Set)')\n",
        "# Place the legend in the plot's lower right corner.\n",
        "mtplt.legend(loc=\"lower right\")\n",
        "# Show the graph on the screen.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcnBjuG9cf4l"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbC5rxxdZq0_"
      },
      "outputs": [],
      "source": [
        "# Use the trained model to create predicted categories for the unknown dataset.\n",
        "y_pred_catboost = catboost_model.predict(X_test)\n",
        "# Determine the expected probabilities for the positive category for the samples that are not visible.\n",
        "y_pred_prob_catboost = catboost_model.predict_proba(X_test)[:, 1] # Probability of the positive class\n",
        "# Show a header stating that the model's performance on fresh data is related to the following outputs.\n",
        "print(\"\\nCatBoost Classifier Results:\")\n",
        "# Calculate and display the percentage of instances that were correctly detected in each test scenario.\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_catboost))\n",
        "# Determine and display the proportion of accurately detected positives to all positive forecasts.\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_catboost))\n",
        "# Display the percentage of real positive cases that the model was able to capture.\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_catboost))\n",
        "# As a fair indicator of model performance, show the harmonic mean of precision and recall.\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_catboost))\n",
        "# Using probabilities, compute and output the summary metric that reflects overall discrimination ability.\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_prob_catboost))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60zkxt0pcjIp"
      },
      "outputs": [],
      "source": [
        "# Create a table that contrasts the unseen dataset's guessed and actual categories.\n",
        "cm_test_catboost = confusion_matrix(y_test, y_pred_catboost)\n",
        "# To enhance visibility, set up a plotting area with precise measurements.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Show a numerical table with color coding, designating rows and columns for actual and anticipated categories.\n",
        "sbrn.heatmap(cm_test_catboost, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
        "            yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
        "# Include a heading that describes the test subset's categorization summary using the given model.\n",
        "mtplt.title('Confusion Matrix (CatBoost Model - Test Set)')\n",
        "# To indicate the guessed categories, label the horizontal axis.\n",
        "mtplt.xlabel('Predicted Label')\n",
        "# To indicate the actual categories, label the vertical axis.\n",
        "mtplt.ylabel('Actual Label')\n",
        "# Show the completed plan.\n",
        "mtplt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OQTQs7SveIbw"
      },
      "outputs": [],
      "source": [
        "# Based on actual results and anticipated probability, determine the performance curve's x and y coordinates as well as threshold values.\n",
        "fpr_test_catboost, tpr_test_catboost, thresholds_test_catboost = roc_curve(y_test, y_pred_prob_catboost)\n",
        "# Use the area under the curve to calculate the overall model discrimination measure.\n",
        "roc_auc_test_catboost = roc_auc_score(y_test, y_pred_prob_catboost)\n",
        "# To provide clarity, initialize a plotting canvas with the given dimensions.\n",
        "mtplt.figure(figsize=(8, 6))\n",
        "# Use the color, thickness, and label that indicates the computed area to draw the performance curve.\n",
        "mtplt.plot(fpr_test_catboost, tpr_test_catboost, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_test_catboost)\n",
        "# Draw a diagonal reference line with a dashed style and a different color to reflect random guessing.\n",
        "mtplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "# To cover the entire range from zero to one, set boundaries on the horizontal axis.\n",
        "mtplt.xlim([0.0, 1.0])\n",
        "# To improve the visual spacing, set the vertical axis limits a little bit more than 1.\n",
        "mtplt.ylim([0.0, 1.05])\n",
        "# Indicate the rate of false alarms by labeling the horizontal axis.\n",
        "mtplt.xlabel('False Positive Rate')\n",
        "# Indicate the rate of accurately identified positives by labeling the vertical axis.\n",
        "mtplt.ylabel('True Positive Rate')\n",
        "# Include a title that describes the model type and the data chunk it represents.\n",
        "mtplt.title('Receiver Operating Characteristic (ROC) Curve (CatBoost Model - Test Set)')\n",
        "# Include a title that describes the model type and the data chunk it represents.\n",
        "mtplt.legend(loc=\"lower right\")\n",
        "# Display the entire visual representation on the screen.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6TJKS6Akpc7"
      },
      "outputs": [],
      "source": [
        "# Initialize the local interpretability tool tailored for tabular data using the training samples.\n",
        "explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
        "# Provide the array-formatted dataset that was used to fit the model.\n",
        "    training_data=X_train.values,\n",
        "# Indicate the names that go with each input variable.\n",
        "    feature_names=X_train.columns.tolist(),\n",
        "# Specify the labels that stand for the various output categories.\n",
        "    class_names=['Class 0', 'Class 1'],\n",
        "# Configure the mode to deal with classification issues.\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# To interpret the unseen data, pick the first example.\n",
        "instance_index = 0\n",
        "instance = X_test.iloc[instance_index]\n",
        "# Using the specified interpreter, create a local explanation for the selected example.\n",
        "explanation_lime = explainer_lime.explain_instance(\n",
        "# Enter the example's feature values as input.\n",
        "    data_row=instance.values,\n",
        "# Pass the probability prediction function of the model.\n",
        "    predict_fn=catboost_model.predict_proba,\n",
        "# Restrict the explanation to the ten most significant characteristics.\n",
        "    num_features=10\n",
        ")\n",
        "# Show a heading that identifies the example being described.\n",
        "print(f\"\\nLIME Explanation for Instance {instance_index}:\")\n",
        "# Display a condensed table of contributions when rendering the interpretation result inline.\n",
        "explanation_lime.show_in_notebook(show_table=True, show_all=False)\n",
        "# Set up the global interpretability tool for models based on trees.\n",
        "explainer_shap = shap.TreeExplainer(catboost_model)\n",
        "# Select fifty unseen cases at random for analysis.\n",
        "X_sample = X_test.sample(n=50, random_state=42)\n",
        "# Determine each feature's contribution values to the sample's model output.\n",
        "shap_values = explainer_shap.shap_values(X_sample)\n",
        "# Manage the output format by choosing the positive class if contributions are made independently for each class.\n",
        "if isinstance(shap_values, list):\n",
        "    shap_vals_plot = shap_values[1]\n",
        "    expected_val = explainer_shap.expected_value[1]\n",
        "else:\n",
        "# If not, use the equivalent baseline value and the direct output.\n",
        "    shap_vals_plot = shap_values\n",
        "    expected_val = explainer_shap.expected_value\n",
        "\n",
        "# Print a notification that the global summary visualization is about to be displayed.\n",
        "print(\"\\nGlobal SHAP Summary (Bar Plot):\")\n",
        "# Create a horizontal bar chart that shows the sample's average absolute feature contributions.\n",
        "shap.summary_plot(shap_vals_plot, X_sample, plot_type=\"bar\", show=False)\n",
        "# Give the plot a descriptive heading.\n",
        "mtplt.title(\"SHAP Feature Importance (Bar)\")\n",
        "# Show the figure on the screen.\n",
        "mtplt.show()\n",
        "# For a more thorough examination, set the index for a particular sample example.\n",
        "instance_shap_idx = 0\n",
        "# Declare that a thorough force-based explanation of the chosen example will be presented.\n",
        "print(f\"\\nSHAP Force Plot for Instance {instance_shap_idx}:\")\n",
        "# Make a force visualization that illustrates how each variable causes the output of the model to deviate from the baseline.\n",
        "shap.plots.force(\n",
        "    base_value=expected_val,\n",
        "    shap_values=shap_vals_plot[instance_shap_idx],\n",
        "    features=X_sample.iloc[instance_shap_idx],\n",
        "    feature_names=X_sample.columns,\n",
        "    matplotlib=True\n",
        ")\n",
        "# Show the force plot visually.\n",
        "mtplt.show()\n",
        "\n",
        "# Alert the selected instance to the impending choice route visualization.\n",
        "print(\"\\nSHAP Decision Plot for Instance:\")\n",
        "# Create a layered plot that shows how the example's ultimate forecast is the result of accumulated contributions.\n",
        "shap.decision_plot(\n",
        "    base_value=expected_val,\n",
        "    shap_values=shap_vals_plot[instance_shap_idx],\n",
        "    features=X_sample.iloc[instance_shap_idx],\n",
        "    feature_names=list(X_sample.columns)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj6nTCqWjJ74"
      },
      "outputs": [],
      "source": [
        "# Establish a set of evaluation standards for a thorough assessment of model performance.\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "# Using the unseen data and its predictions, determine the performance numbers for the first predictive approach.\n",
        "et_scores = [\n",
        "    accuracy_score(y_test, y_pred_et_final),\n",
        "    precision_score(y_test, y_pred_et_final),\n",
        "    recall_score(y_test, y_pred_et_final),\n",
        "    f1_score(y_test, y_pred_et_final)\n",
        "]\n",
        "# Compile the matching performance metrics that have already been calculated for the second strategy.\n",
        "ann_scores = [accuracy_ann, precision_ann, recall_ann, f1_ann]\n",
        "# Compute similar evaluation results for the third predictive technique on test examples.\n",
        "catboost_scores = [\n",
        "    accuracy_score(y_test, y_pred_catboost),\n",
        "    precision_score(y_test, y_pred_catboost),\n",
        "    recall_score(y_test, y_pred_catboost),\n",
        "    f1_score(y_test, y_pred_catboost)\n",
        "]\n",
        "# Enumerate the three distinct algorithms that are being compared.\n",
        "models = ['Extra Trees', 'ANN', 'CatBoost']\n",
        "# For tabular presentation, arrange the metrics, model identifiers, and related scores in a structured dictionary.\n",
        "scores = {\n",
        "# For every algorithm, repeat the metric names.\n",
        "    'Metric': metrics * len(models),\n",
        "# Copy the model names that go with each metric.\n",
        "    'Model': [model for model in models for _ in metrics],\n",
        "# Sequentially concatenate all metric values.\n",
        "    'Score': et_scores + ann_scores + catboost_scores\n",
        "}\n",
        "# To facilitate manipulation and visualization, convert the dictionary into a tabular data format.\n",
        "scores_cdl = pnds.DataFrame(scores)\n",
        "\n",
        "# To ensure that every element fits clearly, create a plotting area with specified dimensions.\n",
        "fig, ax = mtplt.subplots(figsize=(10, 6))\n",
        "# To manage spacing in the grouped chart, adjust the width of each bar.\n",
        "bar_width = 0.2\n",
        "# Specify each metric category's locations along the horizontal axis.\n",
        "x = npy.arange(len(metrics))\n",
        "# Plot the scores of each algorithm side by side for each evaluation criterion by looping over them.\n",
        "for i, model in enumerate(models):\n",
        "# Retrieve the score values that are pertinent to the present approach.\n",
        "    model_scores = scores_cdl[scores_cdl['Model'] == model]['Score']\n",
        "# To prevent overlap and visually distinguish models, plot vertical bars that are adjusted horizontally.\n",
        "    ax.bar(x + i * bar_width, model_scores, bar_width, label=model)\n",
        "# Include a label explaining the grading criteria shown beneath the graphic.\n",
        "ax.set_xlabel('Evaluation Metric')\n",
        "# Put a label next to the graphic that explains the measuring scale.\n",
        "ax.set_ylabel('Score')\n",
        "# Give a header that explains the meaning of the chart.\n",
        "ax.set_title('Model Comparison on Test Set')\n",
        "# Place the ticks under the grouped bars in the center of the horizontal axis.\n",
        "ax.set_xticks(x + bar_width * (len(models) - 1) / 2)\n",
        "# Using the titles of the evaluation criteria, give these ticks textual labels.\n",
        "ax.set_xticklabels(metrics)\n",
        "# Show a legend that uses the name of the corresponding algorithm to identify each pair of bars.\n",
        "ax.legend()\n",
        "# Modify layout spacing to enhance aesthetics and avoid overlapping parts.\n",
        "mtplt.tight_layout()\n",
        "# To display the finished bar chart, render it.\n",
        "mtplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the best model (CatBoost)\n",
        "with open('best_model.pkl', 'wb') as f:\n",
        "    pickle.dump(catboost_model, f)\n",
        "\n",
        "print(\"Best model (CatBoost) saved as best_model.pkl\")"
      ],
      "metadata": {
        "id": "cRBP-c-y9v0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1hn6vf0QDsHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}